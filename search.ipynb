{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/govind17/Information-Retrieval-Project/blob/main/LDA_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "pt_index_path = 'C:/Users/Pritha/Desktop/SUBJECTS/PROJECT/Relevance feedback with XAI/Backend Code/Information-Retrieval-Project/terrier_cord19'\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer\n",
    "    indexer = pt.index.IterDictIndexer(pt_index_path)\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record\n",
    "    index_ref = indexer.index(cord19.get_corpus_iter(),\n",
    "                              fields=('abstract',),\n",
    "                              meta=('docno',))\n",
    "else:\n",
    "    # if you already have the index, use it.\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "    index = pt.IndexFactory.of(index_ref)\n"
   ],
   "metadata": {
    "id": "ZqTjeAaDs9aI",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pritha\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "monoT5:   0%|          | 0/3 [00:00<?, ?batches/s]Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "monoT5: 100%|██████████| 3/3 [00:12<00:00,  4.19s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['docno', 'title', 'abstract_x', 'summary', 'key_phrases', 'qid',\n",
      "       'docid', 'query', 'abstract_y', 'score', 'rank'],\n",
      "      dtype='object')\n",
      "Index(['docno', 'title', 'abstract', 'summary', 'KeyList'], dtype='object')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      docno                                              title  \\\n",
      "0  awitk3se  COVID-19 (Novel Coronavirus 2019) - recent tre...   \n",
      "1  s4dqx9en  Plasma Metabolomic and Lipidomic Alterations A...   \n",
      "2  u56ydlve  The impact of believing you have had COVID-19 ...   \n",
      "3  3kmxzbm7  COVID-19 (Novel Coronavirus 2019) - recent trends   \n",
      "4  l2rmmjqb  Validation of the British Society of Thoracic ...   \n",
      "5  zub7xdi9  Comparison of the computed tomography findings...   \n",
      "6  rxd08ouk  Cognitive, Affective, and Behavioral Construct...   \n",
      "7  448tamvr  Validation of the British Society of Thoracic ...   \n",
      "8  eyelcflh  Cognitive, Affective, and Behavioral Construct...   \n",
      "9  1loqavom  Stability Analysis and Numerical Simulation of...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  The World Health Organization (WHO) has issued...   \n",
      "1  The pandemic of the coronavirus disease 2019 (...   \n",
      "2  Objectives: To investigate whether people who ...   \n",
      "3  The World Health Organization (WHO) has issued...   \n",
      "4  AIM: To validate the British Society of Thorac...   \n",
      "5  OBJECTIVES: To compare the chest computed tomo...   \n",
      "6  This online survey study aimed to compare the ...   \n",
      "7  Abstract Aim To validate the British Society o...   \n",
      "8  This online survey study aimed to compare the ...   \n",
      "9  The Aim of this research is construct the SEIR...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  COVID-19 is similar to Severe Acute Respirator...   \n",
      "1  COVID-19 is marked by its rapid progression fr...   \n",
      "2  The impact of believing you have had COVID-19 ...   \n",
      "3  COVID-19 is similar to Severe Acute Respirator...   \n",
      "4  Validation of the British Society of Thoracic ...   \n",
      "5  Comparison of the computed tomography findings...   \n",
      "6  In total, 533 sexual minority and 1421 heteros...   \n",
      "7  Validation of the British Society of Thoracic ...   \n",
      "8  In total, 533 sexual minority and 1421 heteros...   \n",
      "9  Stability Analysis and Numerical Simulation of...   \n",
      "\n",
      "                                             KeyList  \n",
      "0  [covid-19, sars-cov, similar, severe acute res...  \n",
      "1  [covid-19, lipid alterations, severe condition...  \n",
      "2  [covid-19, people, social distancing measures,...  \n",
      "3  [covid-19, sars-cov, similar, severe acute res...  \n",
      "4  [covid-19, patients, covid-19 chest radiograph...  \n",
      "5  [covid-19, ggo, bilateral distribution, lower ...  \n",
      "6  [covid-19, sexual minority, heterosexual indiv...  \n",
      "7  [covid-19, patients, covid-19 chest radiograph...  \n",
      "8  [covid-19, sexual minority, heterosexual indiv...  \n",
      "9  [pandemic covid-19, seir model, stability anal...  \n"
     ]
    },
    {
     "data": {
      "text/plain": "      docno                                              title  \\\n0  awitk3se  COVID-19 (Novel Coronavirus 2019) - recent tre...   \n1  s4dqx9en  Plasma Metabolomic and Lipidomic Alterations A...   \n2  u56ydlve  The impact of believing you have had COVID-19 ...   \n3  3kmxzbm7  COVID-19 (Novel Coronavirus 2019) - recent trends   \n4  l2rmmjqb  Validation of the British Society of Thoracic ...   \n5  zub7xdi9  Comparison of the computed tomography findings...   \n6  rxd08ouk  Cognitive, Affective, and Behavioral Construct...   \n7  448tamvr  Validation of the British Society of Thoracic ...   \n8  eyelcflh  Cognitive, Affective, and Behavioral Construct...   \n9  1loqavom  Stability Analysis and Numerical Simulation of...   \n\n                                          abstract_x  \\\n0  The World Health Organization (WHO) has issued...   \n1  The pandemic of the coronavirus disease 2019 (...   \n2  Objectives: To investigate whether people who ...   \n3  The World Health Organization (WHO) has issued...   \n4  AIM: To validate the British Society of Thorac...   \n5  OBJECTIVES: To compare the chest computed tomo...   \n6  This online survey study aimed to compare the ...   \n7  Abstract Aim To validate the British Society o...   \n8  This online survey study aimed to compare the ...   \n9  The Aim of this research is construct the SEIR...   \n\n                                             summary  key_phrases qid   docid  \\\n0  COVID-19 is similar to Severe Acute Respirator...          NaN   1   32226   \n1  COVID-19 is marked by its rapid progression fr...          NaN   1   68320   \n2  The impact of believing you have had COVID-19 ...          NaN   1   75497   \n3  COVID-19 is similar to Severe Acute Respirator...          NaN   1   93863   \n4  Validation of the British Society of Thoracic ...          NaN   1  109749   \n5  Comparison of the computed tomography findings...          NaN   1  112383   \n6  In total, 533 sexual minority and 1421 heteros...          NaN   1  126243   \n7  Validation of the British Society of Thoracic ...          NaN   1  150199   \n8  In total, 533 sexual minority and 1421 heteros...          NaN   1  153035   \n9  Stability Analysis and Numerical Simulation of...          NaN   1  171671   \n\n   query                                         abstract_y     score  rank  \n0  covid  The World Health Organization (WHO) has issued... -0.161107     3  \n1  covid  The pandemic of the coronavirus disease 2019 (... -0.267529     5  \n2  covid  Objectives: To investigate whether people who ... -0.856843     9  \n3  covid  The World Health Organization (WHO) has issued... -0.161107     4  \n4  covid  AIM: To validate the British Society of Thorac... -0.333039     6  \n5  covid  OBJECTIVES: To compare the chest computed tomo... -0.085978     0  \n6  covid  This online survey study aimed to compare the ... -0.112808     1  \n7  covid  Abstract Aim To validate the British Society o... -0.480262     7  \n8  covid  This online survey study aimed to compare the ... -0.112808     2  \n9  covid  The Aim of this research is construct the SEIR... -0.639952     8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>docno</th>\n      <th>title</th>\n      <th>abstract_x</th>\n      <th>summary</th>\n      <th>key_phrases</th>\n      <th>qid</th>\n      <th>docid</th>\n      <th>query</th>\n      <th>abstract_y</th>\n      <th>score</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>awitk3se</td>\n      <td>COVID-19 (Novel Coronavirus 2019) - recent tre...</td>\n      <td>The World Health Organization (WHO) has issued...</td>\n      <td>COVID-19 is similar to Severe Acute Respirator...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>32226</td>\n      <td>covid</td>\n      <td>The World Health Organization (WHO) has issued...</td>\n      <td>-0.161107</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s4dqx9en</td>\n      <td>Plasma Metabolomic and Lipidomic Alterations A...</td>\n      <td>The pandemic of the coronavirus disease 2019 (...</td>\n      <td>COVID-19 is marked by its rapid progression fr...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>68320</td>\n      <td>covid</td>\n      <td>The pandemic of the coronavirus disease 2019 (...</td>\n      <td>-0.267529</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>u56ydlve</td>\n      <td>The impact of believing you have had COVID-19 ...</td>\n      <td>Objectives: To investigate whether people who ...</td>\n      <td>The impact of believing you have had COVID-19 ...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>75497</td>\n      <td>covid</td>\n      <td>Objectives: To investigate whether people who ...</td>\n      <td>-0.856843</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3kmxzbm7</td>\n      <td>COVID-19 (Novel Coronavirus 2019) - recent trends</td>\n      <td>The World Health Organization (WHO) has issued...</td>\n      <td>COVID-19 is similar to Severe Acute Respirator...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>93863</td>\n      <td>covid</td>\n      <td>The World Health Organization (WHO) has issued...</td>\n      <td>-0.161107</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>l2rmmjqb</td>\n      <td>Validation of the British Society of Thoracic ...</td>\n      <td>AIM: To validate the British Society of Thorac...</td>\n      <td>Validation of the British Society of Thoracic ...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>109749</td>\n      <td>covid</td>\n      <td>AIM: To validate the British Society of Thorac...</td>\n      <td>-0.333039</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>zub7xdi9</td>\n      <td>Comparison of the computed tomography findings...</td>\n      <td>OBJECTIVES: To compare the chest computed tomo...</td>\n      <td>Comparison of the computed tomography findings...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>112383</td>\n      <td>covid</td>\n      <td>OBJECTIVES: To compare the chest computed tomo...</td>\n      <td>-0.085978</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>rxd08ouk</td>\n      <td>Cognitive, Affective, and Behavioral Construct...</td>\n      <td>This online survey study aimed to compare the ...</td>\n      <td>In total, 533 sexual minority and 1421 heteros...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>126243</td>\n      <td>covid</td>\n      <td>This online survey study aimed to compare the ...</td>\n      <td>-0.112808</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>448tamvr</td>\n      <td>Validation of the British Society of Thoracic ...</td>\n      <td>Abstract Aim To validate the British Society o...</td>\n      <td>Validation of the British Society of Thoracic ...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>150199</td>\n      <td>covid</td>\n      <td>Abstract Aim To validate the British Society o...</td>\n      <td>-0.480262</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>eyelcflh</td>\n      <td>Cognitive, Affective, and Behavioral Construct...</td>\n      <td>This online survey study aimed to compare the ...</td>\n      <td>In total, 533 sexual minority and 1421 heteros...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>153035</td>\n      <td>covid</td>\n      <td>This online survey study aimed to compare the ...</td>\n      <td>-0.112808</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1loqavom</td>\n      <td>Stability Analysis and Numerical Simulation of...</td>\n      <td>The Aim of this research is construct the SEIR...</td>\n      <td>Stability Analysis and Numerical Simulation of...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>171671</td>\n      <td>covid</td>\n      <td>The Aim of this research is construct the SEIR...</td>\n      <td>-0.639952</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "import pandas as pd\n",
    "from keyPhrasification import key_phrasification\n",
    "\n",
    "monoT5 = MonoT5ReRanker(text_field='abstract')\n",
    "dataset = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "\n",
    "def search_query(query):\n",
    "  index_ref2 = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "  index2 = pt.IndexFactory.of(index_ref2)\n",
    "  # print(query)\n",
    "  if not pt.started():\n",
    "      pt.init()\n",
    "  br = pt.BatchRetrieve(index2) % 10\n",
    "  pipeline = (br >> pt.text.get_text(dataset, 'abstract') >> monoT5)\n",
    "  search_result = pipeline.search(query)\n",
    "  # print(search_result)\n",
    "  cord19_docs = pd.read_csv('/Users/Pritha/Desktop/SUBJECTS/PROJECT/Relevance feedback with XAI/Backend Code/Information-Retrieval-Project/cord19_sum.csv')\n",
    "  filtered_docs = pd.merge(cord19_docs, search_result, on = \"docno\", how = \"inner\")\n",
    "  searchResultswithkeys = key_phrasification(filtered_docs)\n",
    "  print(searchResultswithkeys)\n",
    "  return filtered_docs\n",
    "\n",
    "search_query('covid')"
   ],
   "metadata": {
    "id": "K1L5hBv_s9aP",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/boudinfl/pke.git\n",
      "  Cloning https://github.com/boudinfl/pke.git to c:\\users\\pritha\\appdata\\local\\temp\\pip-req-build-qn3sensy\n",
      "  Resolved https://github.com/boudinfl/pke.git to commit 8f1d05dcc52041c9920ba0f9d5231fe6086d12c4\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (3.6.5)\n",
      "Requirement already satisfied: networkx in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (2.6.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (0.24.2)\n",
      "Requirement already satisfied: unidecode in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (1.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (0.18.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: spacy>=3.2.3 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pke==2.0.0) (3.3.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (0.6.1)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-win_amd64.whl (1.9 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git 'C:\\Users\\Pritha\\AppData\\Local\\Temp\\pip-req-build-qn3sensy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ---------------------------------------- 1.9/1.9 MB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (2.26.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (8.0.15)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from nltk->pke==2.0.0) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from nltk->pke==2.0.0) (2021.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from scikit-learn->pke==2.0.0) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy>=3.2.3->pke==2.0.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy>=3.2.3->pke==2.0.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=3.2.3->pke==2.0.0) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.1)\n",
      "Building wheels for collected packages: pke\n",
      "  Building wheel for pke (setup.py): started\n",
      "  Building wheel for pke (setup.py): finished with status 'done'\n",
      "  Created wheel for pke: filename=pke-2.0.0-py3-none-any.whl size=6160774 sha256=a9bd6b412b16705aa0ca36f4fe171c58e3c977a734de073e2b57272dad626bea\n",
      "  Stored in directory: C:\\Users\\Pritha\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-c2oi0mpj\\wheels\\d5\\46\\97\\85535b5b449f70b6a3c8d1138ce8587345876891e25bfe7954\n",
      "Successfully built pke\n",
      "Installing collected packages: pydantic, pke\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.2\n",
      "    Uninstalling pydantic-1.10.2:\n",
      "      Successfully uninstalled pydantic-1.10.2\n",
      "Successfully installed pke-2.0.0 pydantic-1.8.2\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pritha\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.20.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.62.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (58.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pritha\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 22:47:58.662787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-12-12 22:47:58.663095: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/boudinfl/pke.git\n",
    "!pip install matplotlib\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!pip install -U Flask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5022\n",
      " * Running on http://192.168.0.101:5022\n",
      "\u001B[33mPress CTRL+C to quit\u001B[0m\n",
      "192.168.0.101 - - [29/Dec/2022 18:22:10] \"GET /query?searchString=c HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   qid   docid     docno                                              query  \\\n",
      "0    1  112383  zub7xdi9  OBJECTIVES: To compare the chest computed tomo...   \n",
      "1    1  126243  rxd08ouk  This online survey study aimed to compare the ...   \n",
      "2    1       1    153035                                           eyelcflh   \n",
      "3    1   32226  awitk3se  The World Health Organization (WHO) has issued...   \n",
      "4    1   93863  3kmxzbm7  The World Health Organization (WHO) has issued...   \n",
      "5    1   68320  s4dqx9en  The pandemic of the coronavirus disease 2019 (...   \n",
      "6    1  109749  l2rmmjqb  AIM: To validate the British Society of Thorac...   \n",
      "7    1  150199  448tamvr  Abstract Aim To validate the British Society o...   \n",
      "8    1  171671  1loqavom  The Aim of this research is construct the SEIR...   \n",
      "9    1   75497  u56ydlve  Objectives: To investigate whether people who ...   \n",
      "\n",
      "                                            abstract     score  rank  \n",
      "0                               -0.08597832918167114  0.000000   NaN  \n",
      "1                                -0.1128079742193222  1.000000   NaN  \n",
      "2  This online survey study aimed to compare the ... -0.112808   2.0  \n",
      "3                               -0.16110728681087494  3.000000   NaN  \n",
      "4                               -0.16110728681087494  4.000000   NaN  \n",
      "5                                -0.2675289511680603  5.000000   NaN  \n",
      "6                                -0.3330390751361847  6.000000   NaN  \n",
      "7                               -0.48026177287101746  7.000000   NaN  \n",
      "8                                -0.6399515271186829  8.000000   NaN  \n",
      "9                                -0.8568432331085205  9.000000   NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.0.101 - - [29/Dec/2022 19:05:25] \"GET /query?searchString=c HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      docno                                              title  \\\n",
      "0  awitk3se  COVID-19 (Novel Coronavirus 2019) - recent tre...   \n",
      "1  s4dqx9en  Plasma Metabolomic and Lipidomic Alterations A...   \n",
      "2  u56ydlve  The impact of believing you have had COVID-19 ...   \n",
      "3  3kmxzbm7  COVID-19 (Novel Coronavirus 2019) - recent trends   \n",
      "4  l2rmmjqb  Validation of the British Society of Thoracic ...   \n",
      "5  zub7xdi9  Comparison of the computed tomography findings...   \n",
      "6  rxd08ouk  Cognitive, Affective, and Behavioral Construct...   \n",
      "7  448tamvr  Validation of the British Society of Thoracic ...   \n",
      "8  eyelcflh  Cognitive, Affective, and Behavioral Construct...   \n",
      "9  1loqavom  Stability Analysis and Numerical Simulation of...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  The World Health Organization (WHO) has issued...   \n",
      "1  The pandemic of the coronavirus disease 2019 (...   \n",
      "2  Objectives: To investigate whether people who ...   \n",
      "3  The World Health Organization (WHO) has issued...   \n",
      "4  AIM: To validate the British Society of Thorac...   \n",
      "5  OBJECTIVES: To compare the chest computed tomo...   \n",
      "6  This online survey study aimed to compare the ...   \n",
      "7  Abstract Aim To validate the British Society o...   \n",
      "8  This online survey study aimed to compare the ...   \n",
      "9  The Aim of this research is construct the SEIR...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  COVID-19 is similar to Severe Acute Respirator...   \n",
      "1  COVID-19 is marked by its rapid progression fr...   \n",
      "2  The impact of believing you have had COVID-19 ...   \n",
      "3  COVID-19 is similar to Severe Acute Respirator...   \n",
      "4  Validation of the British Society of Thoracic ...   \n",
      "5  Comparison of the computed tomography findings...   \n",
      "6  In total, 533 sexual minority and 1421 heteros...   \n",
      "7  Validation of the British Society of Thoracic ...   \n",
      "8  In total, 533 sexual minority and 1421 heteros...   \n",
      "9  Stability Analysis and Numerical Simulation of...   \n",
      "\n",
      "                                             KeyList  \n",
      "0  ['covid-19', 'sars-cov', 'similar', 'severe ac...  \n",
      "1  ['covid-19', 'lipid alterations', 'severe cond...  \n",
      "2  ['covid-19', 'people', 'social distancing meas...  \n",
      "3  ['covid-19', 'sars-cov', 'similar', 'severe ac...  \n",
      "4  ['covid-19', 'patients', 'covid-19 chest radio...  \n",
      "5  ['covid-19', 'ggo', 'bilateral distribution', ...  \n",
      "6  ['covid-19', 'sexual minority', 'heterosexual ...  \n",
      "7  ['covid-19', 'patients', 'covid-19 chest radio...  \n",
      "8  ['covid-19', 'sexual minority', 'heterosexual ...  \n",
      "9  ['pandemic covid-19', 'seir model', 'stability...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.0.101 - - [29/Dec/2022 19:06:07] \"OPTIONS /feedback HTTP/1.1\" 200 -\n",
      "192.168.0.101 - - [29/Dec/2022 19:06:07] \"POST /feedback HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'docno': 'rxd08ouk', 'keyList': \"['covid-19', 'sexual minority', 'heterosexual individuals', 'covid-19 health beliefs', 'behavioral constructs']\", 'abstract': 'This online survey study aimed to compare the cognitive, affective, and behavioral constructs of health beliefs related to coronavirus disease 2019 (COVID-19) between sexual minority and heterosexual individuals in Taiwan. In total, 533 sexual minority and 1421 heterosexual participants were recruited through a Facebook advertisement. The constructs pertaining to cognition (perceived relative susceptibility to COVID-19, perceived COVID-19 severity, having sufficient knowledge and information on COVID-19, and confidence in coping with COVID-19), affect (worry toward COVID-19), and behavior (adoption of health-protective behaviors) in relation to health beliefs about COVID-19 were compared between sexual minority and heterosexual participants. The results indicated that sexual minority participants had lower perceived susceptibility to COVID-19, greater self-confidence in coping with COVID-19, and lower worry about COVID-19 and were less likely to maintain good indoor ventilation and disinfect their household than heterosexual individuals. Sexual orientation is the modifying factor for the Health Belief Model in the COVID-19 pandemic and should be taken into consideration when medical professionals establish prevention programs for COVID-19.', 'summary': 'In total, 533 sexual minority and 1421 heterosexual participants were recruited through a Facebook advertisement. The results indicated that sexual minority participants had lower perceived susceptibility to COVID-19, greater self-confidence in coping with COVID-19, and lower worry about COVID-19 and were less likely to maintain good indoor ventilation and disinfect their household than heterosexual individuals.', 'relevant': True}, {'docno': 'zub7xdi9', 'keyList': \"['covid-19', 'ggo', 'bilateral distribution', 'lower lobes', 'viral pneumonia']\", 'abstract': 'OBJECTIVES: To compare the chest computed tomography (CT) findings of coronavirus disease 2019 (COVID-19) to other non-COVID viral pneumonia. METHODS: MEDLINE, EMBASE, and Cochrane databases were searched through April 04, 2020, for published English language studies. Studies were eligible if they included immunocompetent patients with up to 14 days of viral pneumonia. Subjects had a respiratory tract sample test positive for COVID-19, adenovirus, influenza A, rhinovirus, parainfluenza, or respiratory syncytial virus. We only included observational studies and case series with more than ten patients. The pooled prevalence of each chest CT pattern or finding was calculated with 95% confidence intervals (95% CI). RESULTS: From 2263 studies identified, 33 were eligible for inclusion, with a total of 1911 patients (COVID-19, n = 934; non-COVID, n = 977). Frequent CT features for both COVID-19 and non-COVID viral pneumonia were a mixed pattern of ground-glass opacity (GGO) and consolidation (COVID-19, 0.37; 0.17-0.56; non-COVID, 0.46; 0.35-0.58) or predominantly GGO pattern (COVID-19, 0.42; 0.28-0.55; non-COVID 0.25; 0.17-0.32), bilateral distribution (COVID-19, 0.81; 0.77-0.85; non-COVID, 0.69; 0.54-0.84), and involvement of lower lobes (COVID-19, 0.88; 0.80-0.95; non-COVID, 0.61; 0.50-0.82). COVID-19 pneumonia presented a higher prevalence of peripheral distribution (COVID-19 0.77; 0.67-0.87; non-COVID 0.34; 0.18-0.49), and involvement of upper (COVID-19, 0.77; 0.65-0.88; non-COVID 0.18; 0.10-0.27) and middle lobes (COVID-19, 0.61; 0.47-0.76; non-COVID 0.24; 0.11-0.38). CONCLUSION: Except for a higher prevalence of peripheral distribution, involvement of upper and middle lobes, COVID-19, and non-COVID viral pneumonia had overlapping chest CT findings. KEY POINTS: â\\x80¢ Most common CT findings of coronavirus disease 2019 (COVID-19) were a predominant pattern of ground-glass opacity (GGO), followed by a mixed pattern of GGO and consolidation, bilateral disease, peripheral distribution, and lower lobe involvement. â\\x80¢ Most frequent CT findings of non-COVID viral pneumonia were a predominantly mixed pattern of GGO and consolidation, followed by a predominant pattern of GGO, bilateral disease, random or diffuse distribution, and lower lobe involvement. â\\x80¢ COVID-19 pneumonia presented a higher prevalence of peripheral distribution, and involvement of upper and middle lobes compared with non-COVID viral pneumonia.', 'summary': 'Comparison of the computed tomography findings in COVID-19 and other viral pneumonia in immunocompetent adults: a systematic review and meta-analysis OBJECTIVES: To compare the chest computed tomography (CT) findings of coronavirus disease 2019 (COVID-19) to other non-COVID viral pneumonia. The pooled prevalence of each chest CT pattern or finding was calculated with 95% confidence intervals (95% CI).', 'relevant': True}]\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "import pandas as pd\n",
    "from flask import request\n",
    "from flask_cors import CORS\n",
    "from keyPhrasification import key_phrasification\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "# app.config[\"DEBUG\"] = True\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/query', methods=['GET'])\n",
    "def search():\n",
    "    # query = request.args.get('searchString')\n",
    "    # print(query)\n",
    "    #searchResults = search_query(query)\n",
    "    # print(searchResults.head())\n",
    "    #searchResultswithkeys = key_phrasification(searchResults)\n",
    "    searchResultswithkeys = pd.read_csv('/Users/GovindShukla/Desktop/Information-Retrieval-Project/search_result.csv')\n",
    "    print(searchResultswithkeys)\n",
    "    return searchResultswithkeys.to_json(orient='records')\n",
    "\n",
    "\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def fetchFeedback():\n",
    "    # corpus_df = pd.read_csv(\n",
    "    #     '/Users/GovindShukla/Desktop/Information-Retrieval-Project/RankedDocuments/trec_docs_sample.csv')\n",
    "    # corpus = corpus_df['text'].values\n",
    "    # list = request.args.get('feedbackList')\n",
    "    # # print(request.body)\n",
    "    # print(list)\n",
    "    # return\n",
    "    feedbackJson = request.json['updates']\n",
    "    relevanceList = []\n",
    "    if len(feedbackJson):\n",
    "        for doc in feedbackJson:\n",
    "            for relevance in doc['value']:\n",
    "                relevanceList.append(relevance)\n",
    "    print(relevanceList)\n",
    "    return relevanceList\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     corpus_df = pd.read_csv(\n",
    "#         '/Users/GovindShukla/Desktop/Information-Retrieval-Project/RankedDocuments/trec_docs_sample.csv')\n",
    "#     corpus = corpus_df['text'].values\n",
    "if __name__ == \"__main__\":\n",
    "    # app.debug = True\n",
    "    app.run(host='0.0.0.0',port=5022)\n",
    "#search_result.csv\n",
    "#     from flask import Flask\n",
    "# app = Flask(__name__)\n",
    "#\n",
    "# @app.route(\"/\")\n",
    "# def hello(): return \"Hello World\"\n",
    "#\n",
    "# if __name__ == \"__main__\":\n",
    "#   app.debug = True\n",
    "#   app.run(host='0.0.0.0',port=5005)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###Feedback"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\r\n",
      "  Downloading gensim-4.3.0-cp310-cp310-macosx_10_9_universal2.whl (24.5 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 24.5 MB 5.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.7.0 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from gensim) (1.9.3)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from gensim) (1.22.3)\r\n",
      "Collecting FuzzyTM>=0.4.0\r\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from gensim) (5.2.1)\r\n",
      "Collecting pyfume\r\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 67 kB 6.9 MB/s eta 0:00:011\r\n",
      "\u001B[?25hRequirement already satisfied: pandas in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim) (1.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2021.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\r\n",
      "Collecting simpful\r\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\r\n",
      "Collecting fst-pso\r\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\r\n",
      "Collecting miniful\r\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\r\n",
      "Requirement already satisfied: requests in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.9.24)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/GovindShukla/miniforge3/envs/GSCS/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.1.1)\r\n",
      "Building wheels for collected packages: fst-pso, miniful\r\n",
      "  Building wheel for fst-pso (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20444 sha256=fc14e1f67fb75dc881d94c0c25bef90a3a9a3f4f25a52c5a2b9b23e7339c5994\r\n",
      "  Stored in directory: /Users/GovindShukla/Library/Caches/pip/wheels/2d/1b/42/88a19f6b3896c2230d5053832f208976cddf70625885201d06\r\n",
      "  Building wheel for miniful (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3529 sha256=ddade411c9fbb00634f2901de669473fa06173b351c8f4efb3654f9fe0963522\r\n",
      "  Stored in directory: /Users/GovindShukla/Library/Caches/pip/wheels/5b/86/8f/7bb7f6472e2c84de7addfc1a5cd7fd647f00d8fb640da9ea9a\r\n",
      "Successfully built fst-pso miniful\r\n",
      "Installing collected packages: miniful, simpful, fst-pso, pyfume, FuzzyTM, gensim\r\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 simpful-2.9.0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/GovindShukla/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/GovindShukla/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One time installation\n",
    "!pip install gensim\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#text preprocessing\n",
    "def pre_processing_data(data):\n",
    "    ps = PorterStemmer()\n",
    "    tagged_dataset = [TaggedDocument(words=[ps.stem(w) for w in nltk.word_tokenize(_d) if w.lower() not in stopwords.words('english') and w.isalpha()], tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "    #tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data_set)]\n",
    "    return tagged_dataset\n",
    "\n",
    "def model_doc2vec(model, tagged_data, num_epochs):\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data,total_examples=len(tagged_data), epochs=num_epochs)\n",
    "    return model\n",
    "\n",
    "def vector_for_learning(model, input_docs):\n",
    "    sents = input_docs\n",
    "    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, feature_vectors\n",
    "\n",
    "def define_d2v_model(preprocessed_tagged_dataset):\n",
    "    model_d2v = Doc2Vec(dm=1, vector_size=100, window = 10, negative=5, hs=0, min_count=2, sample = 0, alpha=0.025, min_alpha=0.001, dm_mean = 0, dbow_words=1)\n",
    "    model = model_doc2vec(model_d2v, preprocessed_tagged_dataset, 100)\n",
    "    id, vectors = vector_for_learning(model, preprocessed_tagged_dataset)\n",
    "    return id, vectors\n",
    "\n",
    "def get_vectors(data):\n",
    "    preprocessed_tagged_dataset = pre_processing_data(data)\n",
    "    id, vectors = np.array(define_d2v_model(preprocessed_tagged_dataset), dtype=object)\n",
    "    return vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def compute_cosine_sim(input_data, new_doc_vector, all_data, name):\n",
    "    consine_similarities = []\n",
    "    for index, data in all_data.iterrows():\n",
    "        if(input_data['CelexId'] != data['CelexId']):\n",
    "            if(len(new_doc_vector) == 0):\n",
    "                cosine_sim = cosine_similarity([input_data[name]], [all_data[name][index]])\n",
    "                consine_similarities.append(cosine_sim[0][0])\n",
    "            else:\n",
    "                cosine_sim = cosine_similarity([new_doc_vector], [all_data[name][index]])\n",
    "                consine_similarities.append(cosine_sim[0][0])\n",
    "        else:\n",
    "            consine_similarities.append(-100000000)\n",
    "\n",
    "    return consine_similarities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Rocchio algorithm\n",
    "def rocchio_algorithm(query_doc_vector, docs_relevant_vectors,\n",
    "                      docs_irrelevant_vectors, key_relevant_vectors,\n",
    "                      key_irrelevant_vectors,\n",
    "                      alpha, beta, gamma, delta):\n",
    "\n",
    "    sum_of_rel_doc_vectors = []\n",
    "    sum_of_irrel_doc_vectors =[]\n",
    "    sum_of_rel_key_vectors = []\n",
    "    sum_of_irrel_key_vectors =[]\n",
    "\n",
    "    for each_rel_doc_vector in docs_relevant_vectors:\n",
    "        if (len(sum_of_rel_doc_vectors) == 0):\n",
    "            sum_of_rel_doc_vectors = each_rel_doc_vector\n",
    "        else:\n",
    "            sum_of_rel_doc_vectors = list(map(operator.add, sum_of_rel_doc_vectors, each_rel_doc_vector))\n",
    "\n",
    "    for each_irrel_doc_vector in docs_irrelevant_vectors:\n",
    "        if (len(sum_of_irrel_doc_vectors) == 0):\n",
    "            sum_of_irrel_doc_vectors = each_irrel_doc_vector\n",
    "        else:\n",
    "            sum_of_irrel_doc_vectors = list(map(operator.add, sum_of_irrel_doc_vectors, each_irrel_doc_vector))\n",
    "\n",
    "    for each_rel_key_vector in key_relevant_vectors:\n",
    "        if (len(sum_of_rel_key_vectors) == 0):\n",
    "            sum_of_rel_key_vectors = each_rel_key_vector\n",
    "        else:\n",
    "            sum_of_rel_key_vectors = list(map(operator.add, sum_of_rel_key_vectors, each_rel_key_vector))\n",
    "\n",
    "    for each_irrel_key_vector in key_irrelevant_vectors:\n",
    "        if (len(sum_of_irrel_key_vectors) == 0):\n",
    "            sum_of_irrel_key_vectors = each_irrel_key_vector\n",
    "        else:\n",
    "            sum_of_irrel_key_vectors = list(map(operator.add, sum_of_irrel_key_vectors, each_irrel_key_vector))\n",
    "\n",
    "    new_doc_vector_query = np.array(query_doc_vector)\n",
    "    + ((alpha/len(docs_relevant_vectors)) * np.array(sum_of_rel_doc_vectors))\n",
    "    - ((beta/len(docs_irrelevant_vectors)) * np.array(sum_of_irrel_doc_vectors))\n",
    "    + ((gamma/len(docs_relevant_vectors)) * np.array(sum_of_rel_key_vectors))\n",
    "    - ((delta/len(docs_relevant_vectors)) * np.array(sum_of_irrel_key_vectors))\n",
    "\n",
    "    return new_doc_vector_query"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}