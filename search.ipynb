{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/govind17/Information-Retrieval-Project/blob/main/LDA_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -U Flask\n",
    "# !pip install git+https://github.com/boudinfl/pke.git\n",
    "# !pip install matplotlib\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "!pip install flask-script\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pritha\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Pritha\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Pritha\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pritha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pritha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One time installation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import io\n",
    "# import flask_script\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import flask\n",
    "from flask import request\n",
    "from flask_cors import CORS\n",
    "from flask import Flask, Response\n",
    "from keyPhrasification import key_phrasification\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pyterrier as pt\n",
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import ast\n",
    "from sklearn.manifold import TSNE\n",
    "from keyPhrasification import key_phrasification\n",
    "# from flask_script import Manager\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indexing the cord-19 dataset\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "pt_index_path = 'C:/Users/Pritha/Desktop/SUBJECTS/PROJECT/Relevance feedback with XAI/Backend Code/Information-Retrieval-Project/terrier_cord19'\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer\n",
    "    indexer = pt.index.IterDictIndexer(pt_index_path)\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record\n",
    "    index_ref = indexer.index(cord19.get_corpus_iter(),\n",
    "                              fields=('abstract',),\n",
    "                              meta=('docno',))\n",
    "else:\n",
    "    # if you already have the index, use it.\n",
    "    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "    index = pt.IndexFactory.of(index_ref)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from nltk.tokenize import MWETokenizer\n",
    "#  # function to extract 5 words before and after a given word\n",
    "# def extract_context(text, keyword):\n",
    "#     # split the text into sentences using NLTK's sent_tokenize() function\n",
    "#     # sentences = sent_tokenize(text)\n",
    "#     # # iterate through each sentence\n",
    "#     # context = []\n",
    "#     # for sentence in sentences:\n",
    "#     #     # split the sentence into words using NLTK's word_tokenize() function\n",
    "#     #     words = word_tokenize(sentence)\n",
    "#     #     # check if the keyword is present in the sentence\n",
    "#     #     if keyword in words:\n",
    "#     #         # find the index of the keyword in the sentence\n",
    "#     #         keyword_index = words.index(keyword)\n",
    "#     #         # find the start and end indices for the context\n",
    "#     #         start_index = max(0, keyword_index - 5)\n",
    "#     #         end_index = min(len(words), keyword_index + 6)\n",
    "#     #         # extract the context and join the words together\n",
    "#     #         context.append(' '.join(words[start_index:end_index]))\n",
    "#     # # join the contexts for each sentence together\n",
    "#     # return ' '.join(context) if context else ''from nltk import sent_tokenize, word_tokenize\n",
    "#\n",
    "# # def extract_context(text, keyword):\n",
    "#     # split the text into sentences using NLTK's sent_tokenize() function\n",
    "#     from nltk import sent_tokenize\n",
    "# from nltk.tokenize import word_tokenize\n",
    "#\n",
    "# def extract_context(text, keyword):\n",
    "#     # split the text into sentences using NLTK's sent_tokenize() function\n",
    "#     sentences = sent_tokenize(text)\n",
    "#     # iterate through each sentence\n",
    "#     context = []\n",
    "#     for sentence in sentences:\n",
    "#         # tokenize the sentence into phrases using NLTK's word_tokenize() function\n",
    "#         phrases = word_tokenize(sentence.lower())\n",
    "#         # check if the keyword is present in the sentence\n",
    "#         if keyword.lower() in ' '.join(phrases):\n",
    "#             # find the index of the keyword in the sentence\n",
    "#             keyword_index = phrases.index(keyword.lower())\n",
    "#             # find the start and end indices for the context\n",
    "#             start_index = max(0, keyword_index - 5)\n",
    "#             end_index = min(len(phrases), keyword_index + 6)\n",
    "#             # extract the context and join the phrases together\n",
    "#             context.append(' '.join(phrases[start_index:end_index]))\n",
    "#     # join the contexts for each sentence together\n",
    "#     return ' '.join(context) if context else ''\n",
    "\n",
    "def extract_context_from_keylist(keylist, abstract):\n",
    "    result = []\n",
    "    for key in keylist:\n",
    "        result.append(extract_context(abstract, key))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, ngrams\n",
    "\n",
    "def extract_context(text, keyword):\n",
    "    # split the text into sentences using NLTK's sent_tokenize() function\n",
    "    sentences = sent_tokenize(text)\n",
    "    # iterate through each sentence\n",
    "    context = []\n",
    "    for sentence in sentences:\n",
    "        # tokenize the sentence into n-grams using NLTK's ngrams() function\n",
    "        words = sentence.lower().split()\n",
    "        ngram_list = list(ngrams(words, len(keyword.split())))\n",
    "        # check if the keyword is present in the sentence\n",
    "        if any([keyword.lower() in ' '.join(ngram).replace(\",\", \"\") for ngram in ngram_list]):\n",
    "            # find the start and end indices for the context\n",
    "            keyword_indices = [i for i, ngram in enumerate(ngram_list) if keyword.lower() in ' '.join(ngram).replace(\",\", \"\")]\n",
    "            start_index = max(0, min(keyword_indices) - 5)\n",
    "            end_index = min(len(ngram_list), max(keyword_indices) + 6)\n",
    "            # extract the context and join the words together\n",
    "            phrase = ' '.join([' '.join(word) for word in ngram_list[start_index:end_index]])\n",
    "            # add unique words to the context in the order they appear in the original text\n",
    "            for word in phrase.split():\n",
    "                if word not in context:\n",
    "                    context.append(word)\n",
    "    # join the final context into a single string\n",
    "    return ''.join(context)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#text preprocessing\n",
    "def pre_processing_data(data):\n",
    "    ps = PorterStemmer()\n",
    "    tagged_dataset = [TaggedDocument(words=[ps.stem(w) for w in nltk.word_tokenize(str(_d)) if word_tokenize(str(_d).lower()) not in stopwords.words('english')], tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "    #tagged_dataset = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "    return tagged_dataset\n",
    "\n",
    "def model_doc2vec(model, tagged_data, num_epochs):\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data,total_examples=len(tagged_data), epochs=num_epochs)\n",
    "    return model\n",
    "\n",
    "def vector_for_learning(model, input_docs):\n",
    "    sents = input_docs\n",
    "    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words)) for doc in sents])\n",
    "    return targets, feature_vectors\n",
    "\n",
    "def define_d2v_model(dataset):\n",
    "    preprocessed_tagged_dataset = pre_processing_data(dataset)\n",
    "    model_d2v = Doc2Vec(dm=1, vector_size=100, window = 10, negative=5, hs=0, min_count=2, sample = 0, alpha=0.025, min_alpha=0.001, dm_mean = 0, dbow_words=1)\n",
    "    model = model_doc2vec(model_d2v, preprocessed_tagged_dataset, 100)\n",
    "    return model\n",
    "\n",
    "def get_vectors(input_data, model):\n",
    "    preprocessed_tagged_input_data= pre_processing_data(input_data)\n",
    "    id, vectors = np.array(vector_for_learning(model, preprocessed_tagged_input_data), dtype=object)\n",
    "    return vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Rocchio algorithm\n",
    "def rocchio_algorithm(query_doc_vector, docs_relevant_vectors,\n",
    "                      docs_irrelevant_vectors, key_relevant_vectors,\n",
    "                      key_irrelevant_vectors,\n",
    "                      alpha, beta, gamma, delta):\n",
    "\n",
    "    # sum_of_rel_doc_vectors = docs_relevant_vectors.sum(axis=0)\n",
    "    # print('sum_of_rel_doc_vectors', sum_of_rel_doc_vectors)\n",
    "    sum_of_rel_doc_vectors=[]\n",
    "    sum_of_irrel_doc_vectors=[]\n",
    "    sum_of_rel_key_vectors=[]\n",
    "    sum_of_irrel_key_vectors=[]\n",
    "    for each_rel_doc_vector in docs_relevant_vectors:\n",
    "        if len(sum_of_rel_doc_vectors) == 0:\n",
    "            # print('Length of sum_of_rel_doc_vectors is zero')\n",
    "            sum_of_rel_doc_vectors = each_rel_doc_vector\n",
    "        else:\n",
    "            # print(each_rel_doc_vector)\n",
    "            sum_of_rel_doc_vectors = list(map(operator.add, sum_of_rel_doc_vectors, each_rel_doc_vector))\n",
    "            # print('SUM :', sum_of_rel_doc_vectors)\n",
    "    for each_irrel_doc_vector in docs_irrelevant_vectors:\n",
    "        if len(sum_of_irrel_doc_vectors) == 0:\n",
    "            sum_of_irrel_doc_vectors = each_irrel_doc_vector\n",
    "        else:\n",
    "            sum_of_irrel_doc_vectors = list(map(operator.add, sum_of_irrel_doc_vectors, each_irrel_doc_vector))\n",
    "    # sum_of_irrel_doc_vectors = docs_irrelevant_vectors.sum(axis=0)\n",
    "    # print('sum_of_irrel_doc_vectors', sum_of_irrel_doc_vectors)\n",
    "    for each_rel_key_vector in key_relevant_vectors:\n",
    "        if len(sum_of_rel_key_vectors) == 0:\n",
    "            sum_of_rel_key_vectors = each_rel_key_vector\n",
    "        else:\n",
    "            sum_of_rel_key_vectors = list(map(operator.add, sum_of_rel_key_vectors, each_rel_key_vector))\n",
    "    # sum_of_rel_key_vectors = key_relevant_vectors.sum(axis=0)\n",
    "    # print('sum_of_rel_key_vectors', sum_of_rel_key_vectors)\n",
    "    for each_irrel_key_vector in key_irrelevant_vectors:\n",
    "        if len(sum_of_irrel_key_vectors) == 0:\n",
    "            sum_of_irrel_key_vectors = each_irrel_key_vector\n",
    "        else:\n",
    "            sum_of_irrel_key_vectors = list(map(operator.add, sum_of_irrel_key_vectors, each_irrel_key_vector))\n",
    "    # sum_of_irrel_key_vectors = key_irrelevant_vectors.sum(axis=0)\n",
    "    # print('sum_of_irrel_key_vectors', (delta/len(docs_relevant_vectors)) * np.array(sum_of_irrel_key_vectors))\n",
    "\n",
    "    new_doc_vector_query = np.sum([np.array(query_doc_vector)\n",
    "    , (alpha/len(docs_relevant_vectors)) * np.array(sum_of_rel_doc_vectors)\n",
    "    , (beta/len(docs_irrelevant_vectors)) * np.array(sum_of_irrel_doc_vectors)\n",
    "    , (gamma/len(docs_relevant_vectors)) * np.array(sum_of_rel_key_vectors)\n",
    "    , (delta/len(docs_relevant_vectors)) * np.array(sum_of_irrel_key_vectors)], axis=0)\n",
    "    df = pd.DataFrame({\"a\": [new_doc_vector_query]})\n",
    "    return df.values\n",
    "\n",
    "# Compute cosine scores\n",
    "def compute_cosine_sim(new_query_vector, all_data, name):\n",
    "    consine_similarities = []\n",
    "    for index, data in all_data.iterrows():\n",
    "        cosine_sim = cosine_similarity([np.array(new_query_vector[0])], [np.array(all_data[name][index])])\n",
    "        consine_similarities.append(cosine_sim[0][0])\n",
    "    return consine_similarities\n",
    "\n",
    "# Rank data\n",
    "def rank_data(new_query_vector, dataset, name, a, b):\n",
    "    ps = PorterStemmer()\n",
    "    cosine_sim_values = compute_cosine_sim(new_query_vector, dataset, name)\n",
    "    dataset['Cosine_Similarity_' + name] = cosine_sim_values\n",
    "    # dataset.drop(dataset[dataset['bntStyle'] == False].index, inplace=True)\n",
    "    # dataset['KeyList'] = dataset['KeyList'].apply(ast.literal_eval)\n",
    "    rel_keyList_df = dataset['KeyList'][dataset['relevant'] == True]\n",
    "    relevant_KeyList = []\n",
    "    for lst in rel_keyList_df:\n",
    "        lst = list(map(lambda word: ps.stem(word), lst))\n",
    "        relevant_KeyList.extend(lst)\n",
    "\n",
    "    # dataset['Key_word_match_count'] = 0\n",
    "    dataset['Keyword_match_dict'] = [{} for _ in range(len(dataset))]\n",
    "    dataset['Key_word_match_count'] = 0\n",
    "    columns_to_search = ['context_key_1', 'context_key_2', 'context_key_3', 'context_key_4', 'context_key_5']\n",
    "    for i, row in dataset.iterrows():\n",
    "        for col in dataset[columns_to_search].columns:\n",
    "            if row[col] is None:\n",
    "                continue\n",
    "            key_match_dict = {key: 0 for key in relevant_KeyList}\n",
    "            words = [ps.stem(w.lower()) for w in nltk.word_tokenize(row[col])]\n",
    "            for word in relevant_KeyList:\n",
    "                word_list = word.split()\n",
    "                set1 = set(word_list)\n",
    "                set2 = set(words)\n",
    "                if set1.intersection(set2):\n",
    "                    key_match_dict[word] += 1\n",
    "                    dataset.at[i, 'Key_word_match_count']+=1\n",
    "            dataset.at[i, 'Keyword_match_dict'] = key_match_dict\n",
    "    # columns_to_search = ['context_key_1', 'context_key_2', 'context_key_3', 'context_key_4', 'context_key_5']\n",
    "    # for i, row in dataset.iterrows():\n",
    "    #     for col in dataset[columns_to_search].columns:\n",
    "    #         if row[col] is None:\n",
    "    #             continue\n",
    "    #         words = [ps.stem(w.lower()) for w in nltk.word_tokenize(row[col])]\n",
    "    #         for word in relevant_KeyList:\n",
    "    #             word_list = word.split()\n",
    "    #             set1 = set(word_list)\n",
    "    #             set2 = set(words)\n",
    "    #             if set1.intersection(set2):\n",
    "    #                 dataset.at[i, 'Key_word_match_count'] += 1\n",
    "    # dataset['feedback_score'] = dataset['Key_word_match_count']/5 + dataset['Cosine_Similarity_' + name]\n",
    "    dataset['feedback_score'] = a * dataset['Cosine_Similarity_' + name] / np.linalg.norm(dataset['Cosine_Similarity_' + name]) + b * dataset['Key_word_match_count'] / np.linalg.norm(dataset['Key_word_match_count'])\n",
    "    # sorted_dataset = dataset.sort_values(by=['feedback_score'], ascending=False)\n",
    "    sorted_dataset = dataset.sort_values(by=['feedback_score'], ascending=False)\n",
    "    return sorted_dataset\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pritha\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "monoT5 = MonoT5ReRanker(text_field='abstract')\n",
    "dataset = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "cord19_df = pd.read_csv('C:/Users/Pritha/Desktop/SUBJECTS/PROJECT/Relevance feedback with XAI/Backend Code/Information-Retrieval-Project/cord19_context.csv')\n",
    "# model = define_d2v_model(cord19_df['abstract'])\n",
    "model = joblib.load('gensim_model_300.pkl')\n",
    "query_df = pd.DataFrame\n",
    "reranked_df = pd.DataFrame\n",
    "\n",
    "def search_query(query, name):\n",
    "  index_ref2 = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "  index2 = pt.IndexFactory.of(index_ref2)\n",
    "  # print(query)\n",
    "  if not pt.started():\n",
    "      pt.init()\n",
    "  br = pt.BatchRetrieve(index2) % 50\n",
    "  pipeline = (br >> pt.text.get_text(dataset, 'abstract') >> monoT5)\n",
    "  search_result = pipeline.search(query)\n",
    "  # print(search_result)\n",
    "  search_result = search_result.drop_duplicates(subset=['docno'])\n",
    "  # search_result = search_result.drop_duplicates(subset=['summary'])\n",
    "\n",
    "  filtered_docs = pd.merge(cord19_df, search_result, on = \"docno\", how = \"inner\")\n",
    "  filtered_docs.rename(columns={'abstract_x':'abstract'}, inplace=True)\n",
    "  filtered_docs.drop(columns='abstract_y', axis=1, inplace=True)\n",
    "  filtered_docs['KeyList'] = filtered_docs['KeyList'].apply(ast.literal_eval)\n",
    "  # filtered_docs.to_csv('search_result_covid.csv')\n",
    "    # filtered_docs.to_csv('search_result_cough.csv')\n",
    "    # filtered_docs.to_csv('search_result_pandemic.csv')\n",
    "  filtered_docs.to_csv(name)\n",
    "    # filtered_docs.to_csv('search_result_pandemicDeath.csv')\n",
    "    # filtered_docs.to_csv('search_result_hosBedAvb.csv')\n",
    "  # filtered_docs = filtered_docs.drop_duplicates(subset=['docno', 'summary'])\n",
    "  # return filtered_docs\n",
    "  return filtered_docs\n",
    "\n",
    "\n",
    "# search_query('covid')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_reranking(feedback_df : pd.DataFrame, a, b):\n",
    "    global  query_df\n",
    "    feedback_df[\"doc_vec\"] = get_vectors(feedback_df['abstract'], model)\n",
    "    feedback_df[\"keyList_vec\"] = get_vectors(feedback_df['KeyList'], model)\n",
    "    relevant_df = feedback_df.head(10).loc[feedback_df['relevant'] == True]\n",
    "    irrelevant_df = feedback_df.head(10).loc[feedback_df['relevant'] == False]\n",
    "    query_df[\"query_vec\"]  = get_vectors(query_df['query'].values, model)\n",
    "    query_df['new_query_vec'] = rocchio_algorithm(query_df[\"query_vec\"][0], relevant_df[\"doc_vec\"].values, irrelevant_df[\"doc_vec\"].values, relevant_df[\"keyList_vec\"].values, irrelevant_df[\"keyList_vec\"].values, 1.0, 0.5,1.0, 0.5)\n",
    "    sorted_dataset = rank_data(query_df['new_query_vec'].values, feedback_df, \"keyList_vec\", a, b)\n",
    "    return sorted_dataset\n",
    "\n",
    "def generate_plot():\n",
    "    rel_vecs = []\n",
    "    irrel_vecs = []\n",
    "    new_reranked_rel_vecs = []\n",
    "    # plt.canvas.flush_events()\n",
    "    print(\"Reranked DF: \", reranked_df)\n",
    "    for i, data in enumerate(reranked_df.loc[reranked_df['relevant'] == True]['keyList_vec'].values):\n",
    "        rel_vecs.append(data)\n",
    "    for i, data in enumerate(reranked_df.loc[reranked_df['bntStyle'] == False]['keyList_vec'].values):\n",
    "        irrel_vecs.append(data)\n",
    "    for i, data in enumerate(reranked_df.head(10).loc[reranked_df['relevant'] == False]['keyList_vec'].values):\n",
    "        new_reranked_rel_vecs.append(data)\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_rel = pca.fit_transform(rel_vecs)\n",
    "    print(\"Irrelevant vecs: \",irrel_vecs)\n",
    "    pca_irrel = pca.fit_transform(irrel_vecs)\n",
    "    pca_new_rel = pca.fit_transform(new_reranked_rel_vecs)\n",
    "    query =np.concatenate(([np.array(query_df.iloc[0]['query_vec'])], [np.array(query_df.iloc[0]['new_query_vec'])]), axis=0)\n",
    "    pca_query = pca.fit_transform(query)\n",
    "    fig = Figure()\n",
    "    axis = fig.add_subplot(1, 1, 1)\n",
    "    axis.scatter(pca_rel[:,0], pca_rel[:,1], marker=\"8\", label=\"relevant\")\n",
    "    axis.scatter(pca_irrel[:,0], pca_irrel[:,1], marker=\"*\", label=\"irrelevant\")\n",
    "    axis.scatter(pca_new_rel[:,0], pca_new_rel[:,1], color='yellow', marker=\"d\", label=\"new relevant\")\n",
    "    axis.scatter(pca_query[0][0], pca_query[0][1], marker=\"s\", label=\"old_query\")\n",
    "    axis.scatter(pca_query[1][0], pca_query[1][1], marker=\"s\", label=\"new_query\")\n",
    "    axis.set_xlabel(\"PCA 1\")\n",
    "    axis.set_ylabel(\"PCA 2\")\n",
    "    axis.set_title(\"Visualization of vectors\")\n",
    "    axis.axvline(x=0, color='gray', linestyle='--')\n",
    "    axis.legend()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def generate_plot2():\n",
    "    rel_vecs = []\n",
    "    irrel_vecs = []\n",
    "    new_reranked_rel_vecs = []\n",
    "    print(\"Reranked DF: \", reranked_df)\n",
    "    for i, data in enumerate(reranked_df.loc[reranked_df['relevant'] == True]['keyList_vec'].values):\n",
    "        rel_vecs.append(data)\n",
    "    for i, data in enumerate(reranked_df.loc[reranked_df['bntStyle'] == False]['keyList_vec'].values):\n",
    "        irrel_vecs.append(data)\n",
    "    for i, data in enumerate(reranked_df.head(10).loc[reranked_df['relevant'] == False]['keyList_vec'].values):\n",
    "        new_reranked_rel_vecs.append(data)\n",
    "    all_vecs = np.concatenate((rel_vecs, irrel_vecs, new_reranked_rel_vecs), axis=0)\n",
    "    pca = TSNE(n_components=2, random_state = 0)\n",
    "    pca_all = pca.fit_transform(all_vecs)\n",
    "    pca_rel = pca_all[:len(rel_vecs)]\n",
    "    pca_irrel = pca_all[len(rel_vecs):len(rel_vecs)+len(irrel_vecs)]\n",
    "    pca_new_rel = pca_all[len(rel_vecs)+len(irrel_vecs):]\n",
    "    query =np.concatenate(([np.array(query_df.iloc[0]['query_vec'])], [np.array(query_df.iloc[0]['new_query_vec'])]), axis=0)\n",
    "    pca_query = pca.fit_transform(query)\n",
    "    fig = Figure()\n",
    "    axis = fig.add_subplot(1, 1, 1)\n",
    "    axis.scatter(pca_rel[:,0], pca_rel[:,1], marker=\"8\", label=\"relevant\")\n",
    "    axis.scatter(pca_irrel[:,0], pca_irrel[:,1], marker=\"*\", label=\"irrelevant\")\n",
    "    axis.scatter(pca_new_rel[:,0], pca_new_rel[:,1], color='yellow', marker=\"d\", label=\"new relevant\")\n",
    "    axis.scatter(pca_query[0][0], pca_query[0][1], marker=\"s\", label=\"old_query\")\n",
    "    axis.scatter(pca_query[1][0], pca_query[1][1], marker=\"s\", label=\"new_query\")\n",
    "    axis.axhline(y=0, linestyle='--', color='gray')\n",
    "    axis.axvline(x=0, linestyle='--', color='gray')\n",
    "    axis.set_xlabel('PCA 1')\n",
    "    axis.set_ylabel('PCA 2')\n",
    "    axis.set_title('Visualization of vectors')\n",
    "    axis.legend()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# function to extract 5 words before and after a given word\n",
    "def extract_context(text, keyword):\n",
    "    # split the text into sentences using NLTK's sent_tokenize() function\n",
    "    sentences = sent_tokenize(text)\n",
    "    # iterate through each sentence\n",
    "    context = []\n",
    "    for sentence in sentences:\n",
    "        # split the sentence into words using NLTK's word_tokenize() function\n",
    "        words = word_tokenize(sentence)\n",
    "        # check if the keyword is present in the sentence\n",
    "        if keyword in words:\n",
    "            # find the index of the keyword in the sentence\n",
    "            keyword_index = words.index(keyword)\n",
    "            # find the start and end indices for the context\n",
    "            start_index = max(0, keyword_index - 5)\n",
    "            end_index = min(len(words), keyword_index + 6)\n",
    "            # extract the context and join the words together\n",
    "            context.append(' '.join(words[start_index:end_index]))\n",
    "    # join the contexts for each sentence together\n",
    "    return ' '.join(context) if context else ''\n",
    "\n",
    "def extract_context_from_keylist(keylist, abstract):\n",
    "    result = []\n",
    "    for key in keylist:\n",
    "        result.append(extract_context(abstract, key))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# cord19_df = pd.read_csv('/Users/GovindShukla/Downloads/cord19_sum_key.csv')\n",
    "#\n",
    "# # Save the model as a pickle in a file\n",
    "# joblib.dump(model, 'gensim_model_2.pkl')\n",
    "# model = joblib.load('/Users/GovindShukla/Desktop/Information-Retrieval-Project/gensim_model_2.pkl')\n",
    "\n",
    "# model = define_d2v_model(cord19_df[~cord19_df['abstract'].isna()]['abstract'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5254\n",
      " * Running on http://192.168.0.15:5254\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandemic death\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2023 14:53:18] \"GET /query?searchString=pandemic%20death HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2023 14:53:25] \"OPTIONS /feedback HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      docno                                              title  \\\n",
      "0  ya9klbbm  Case-based reported mortality associated with ...   \n",
      "1  ao5676lc  Global Mortality Impact of the 1957–1959 Influ...   \n",
      "2  nqc1pduk  Natality Decline and Spatial Variation in Exce...   \n",
      "3  36fljyl2  Age-Specific Excess Mortality Patterns During ...   \n",
      "4  si9ty2dt  Dealing with mass death in disasters and pande...   \n",
      "5  vhghhvnu  Prioritization of Pandemic Influenza Vaccine: ...   \n",
      "6  tw2n8vqv  Seasonal and pandemic influenza during pregnan...   \n",
      "7  h7pteo3e  The 1918–1919 Influenza Pandemic in Portugal: ...   \n",
      "8  g0fu0r8r  Social Class and Excess Mortality in Sweden Du...   \n",
      "9  11r3dnse  Loose Ends in the Epidemiology of the 1918 Pan...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  BACKGROUND: In contrast to seasonal influenza ...   \n",
      "1  Background. Quantitative estimates of the glob...   \n",
      "2  A large body of epidemiologic research has con...   \n",
      "3  Although much progress has been made to uncove...   \n",
      "4  PURPOSE: There are many differences in how aut...   \n",
      "5  Few catastrophes can compare with the global i...   \n",
      "6  Previous studies of fetal death with maternal ...   \n",
      "7  Although the impact of deaths occurring during...   \n",
      "8  Consensus is lacking in the literature about t...   \n",
      "9  In the century since the 1918 influenza pandem...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  BACKGROUND: In contrast to seasonal influenza ...   \n",
      "1  Increases in the mortality rate relative to ba...   \n",
      "2  A large body of epidemiologic research has con...   \n",
      "3  Although much progress has been made to uncove...   \n",
      "4  PURPOSE: There are many differences in how aut...   \n",
      "5  Public health measures such as reduction of cl...   \n",
      "6  We obtained dates and types of influenza vacci...   \n",
      "7  Poisson regression was used to estimate the as...   \n",
      "8  We analyzed individual-level mortality of the ...   \n",
      "9  We analyze age-stratified mortality data from ...   \n",
      "\n",
      "                                             KeyList  \\\n",
      "0  [seasonal influenza epidemics, deaths, extent ...   \n",
      "1  [pandemic-related mortality, influenza pandemi...   \n",
      "2  [influenza pandemic, birth records, death reco...   \n",
      "3  [influenza pandemic, respiratory excess death ...   \n",
      "4  [pandemics, disasters, mass death incidents, d...   \n",
      "5  [pandemic, vaccination, overall population mor...   \n",
      "6     [ili, fetal death, risk, pregnancy, diagnoses]   \n",
      "7  [influenza-related excess mortality, deaths, d...   \n",
      "8  [differences, influenza-associated deaths, exc...   \n",
      "9  [influenza pandemic, high death rates, signatu...   \n",
      "\n",
      "                                       context_key_1  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  death incidents involving disasters and pandem...   \n",
      "5  impact of a severe influenza pandemic . The 19...   \n",
      "6                                               None   \n",
      "7                                               None   \n",
      "8  this study , we analyzed differences in excess...   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_2  \\\n",
      "0  , where the majority of deaths occur amongst e...   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  during mass death incidents involving disaster...   \n",
      "5  USA to set priorities for vaccination in the s...   \n",
      "6                                               None   \n",
      "7  Although the impact of deaths occurring during...   \n",
      "8                                               None   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_3  \\\n",
      "0                                               None   \n",
      "1  of background levels in 39 countries in Europe...   \n",
      "2                                               None   \n",
      "3  relative magnitudes of 3 pandemic waves in the...   \n",
      "4                                               None   \n",
      "5                                               None   \n",
      "6  ) in pregnancy on the risk of fetal death , di...   \n",
      "7                                               None   \n",
      "8                                               None   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_4  \\\n",
      "0                                               None   \n",
      "1  mortality rate was 1.9/10 000 population ( 95 ...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  in how authorities handle the dead during mass...   \n",
      "5                                               None   \n",
      "6  illness ( ILI ) in pregnancy on the risk of fe...   \n",
      "7                                               None   \n",
      "8  pandemic was measured as the number of deaths ...   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_5  qid  docid  \\\n",
      "0                                               None    1    660   \n",
      "1  to estimate pandemic-related mortality in exce...    1   2123   \n",
      "2  We estimated the number of excess deaths and b...    1   3539   \n",
      "3                                               None    1   3778   \n",
      "4  The main objective of this study is to show th...    1   6321   \n",
      "5                                               None    1   7914   \n",
      "6  fetal death , distinguishing between diagnoses...    1  10795   \n",
      "7                                               None    1  12123   \n",
      "8  influenza-associated deaths during the 1918 pa...    1  12124   \n",
      "9                                               None    1  12125   \n",
      "\n",
      "            query     score  rank bntStyle relevanceToggleText  relevant  \n",
      "0  pandemic death -0.090548     3     True            Relevant      True  \n",
      "1  pandemic death -0.057910     0     True            Relevant      True  \n",
      "2  pandemic death -0.141249     9     True            Relevant      True  \n",
      "3  pandemic death -0.145604    10    False          Irrelevant     False  \n",
      "4  pandemic death -0.117807     7    False          Irrelevant     False  \n",
      "5  pandemic death -0.122168     8    False          Irrelevant     False  \n",
      "6  pandemic death -4.994790    42    False          Irrelevant     False  \n",
      "7  pandemic death -0.116042     5    False          Irrelevant     False  \n",
      "8  pandemic death -0.159277    11    False          Irrelevant     False  \n",
      "9  pandemic death -0.116849     6    False          Irrelevant     False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2023 14:54:41] \"POST /feedback HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2023 15:07:57] \"GET /query?searchString=pandemic%20death HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandemic death\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2023 15:08:04] \"OPTIONS /feedback HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      docno                                              title  \\\n",
      "0  ya9klbbm  Case-based reported mortality associated with ...   \n",
      "1  ao5676lc  Global Mortality Impact of the 1957–1959 Influ...   \n",
      "2  nqc1pduk  Natality Decline and Spatial Variation in Exce...   \n",
      "3  36fljyl2  Age-Specific Excess Mortality Patterns During ...   \n",
      "4  si9ty2dt  Dealing with mass death in disasters and pande...   \n",
      "5  vhghhvnu  Prioritization of Pandemic Influenza Vaccine: ...   \n",
      "6  tw2n8vqv  Seasonal and pandemic influenza during pregnan...   \n",
      "7  h7pteo3e  The 1918–1919 Influenza Pandemic in Portugal: ...   \n",
      "8  g0fu0r8r  Social Class and Excess Mortality in Sweden Du...   \n",
      "9  11r3dnse  Loose Ends in the Epidemiology of the 1918 Pan...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  BACKGROUND: In contrast to seasonal influenza ...   \n",
      "1  Background. Quantitative estimates of the glob...   \n",
      "2  A large body of epidemiologic research has con...   \n",
      "3  Although much progress has been made to uncove...   \n",
      "4  PURPOSE: There are many differences in how aut...   \n",
      "5  Few catastrophes can compare with the global i...   \n",
      "6  Previous studies of fetal death with maternal ...   \n",
      "7  Although the impact of deaths occurring during...   \n",
      "8  Consensus is lacking in the literature about t...   \n",
      "9  In the century since the 1918 influenza pandem...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  BACKGROUND: In contrast to seasonal influenza ...   \n",
      "1  Increases in the mortality rate relative to ba...   \n",
      "2  A large body of epidemiologic research has con...   \n",
      "3  Although much progress has been made to uncove...   \n",
      "4  PURPOSE: There are many differences in how aut...   \n",
      "5  Public health measures such as reduction of cl...   \n",
      "6  We obtained dates and types of influenza vacci...   \n",
      "7  Poisson regression was used to estimate the as...   \n",
      "8  We analyzed individual-level mortality of the ...   \n",
      "9  We analyze age-stratified mortality data from ...   \n",
      "\n",
      "                                             KeyList  \\\n",
      "0  [seasonal influenza epidemics, deaths, extent ...   \n",
      "1  [pandemic-related mortality, influenza pandemi...   \n",
      "2  [influenza pandemic, birth records, death reco...   \n",
      "3  [influenza pandemic, respiratory excess death ...   \n",
      "4  [pandemics, disasters, mass death incidents, d...   \n",
      "5  [pandemic, vaccination, overall population mor...   \n",
      "6     [ili, fetal death, risk, pregnancy, diagnoses]   \n",
      "7  [influenza-related excess mortality, deaths, d...   \n",
      "8  [differences, influenza-associated deaths, exc...   \n",
      "9  [influenza pandemic, high death rates, signatu...   \n",
      "\n",
      "                                       context_key_1  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  death incidents involving disasters and pandem...   \n",
      "5  impact of a severe influenza pandemic . The 19...   \n",
      "6                                               None   \n",
      "7                                               None   \n",
      "8  this study , we analyzed differences in excess...   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_2  \\\n",
      "0  , where the majority of deaths occur amongst e...   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  during mass death incidents involving disaster...   \n",
      "5  USA to set priorities for vaccination in the s...   \n",
      "6                                               None   \n",
      "7  Although the impact of deaths occurring during...   \n",
      "8                                               None   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_3  \\\n",
      "0                                               None   \n",
      "1  of background levels in 39 countries in Europe...   \n",
      "2                                               None   \n",
      "3  relative magnitudes of 3 pandemic waves in the...   \n",
      "4                                               None   \n",
      "5                                               None   \n",
      "6  ) in pregnancy on the risk of fetal death , di...   \n",
      "7                                               None   \n",
      "8                                               None   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_4  \\\n",
      "0                                               None   \n",
      "1  mortality rate was 1.9/10 000 population ( 95 ...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  in how authorities handle the dead during mass...   \n",
      "5                                               None   \n",
      "6  illness ( ILI ) in pregnancy on the risk of fe...   \n",
      "7                                               None   \n",
      "8  pandemic was measured as the number of deaths ...   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_5  qid  docid  \\\n",
      "0                                               None    1    660   \n",
      "1  to estimate pandemic-related mortality in exce...    1   2123   \n",
      "2  We estimated the number of excess deaths and b...    1   3539   \n",
      "3                                               None    1   3778   \n",
      "4  The main objective of this study is to show th...    1   6321   \n",
      "5                                               None    1   7914   \n",
      "6  fetal death , distinguishing between diagnoses...    1  10795   \n",
      "7                                               None    1  12123   \n",
      "8  influenza-associated deaths during the 1918 pa...    1  12124   \n",
      "9                                               None    1  12125   \n",
      "\n",
      "            query     score  rank bntStyle relevanceToggleText  relevant  \n",
      "0  pandemic death -0.090548     3     True            Relevant      True  \n",
      "1  pandemic death -0.057910     0     True            Relevant      True  \n",
      "2  pandemic death -0.141249     9     True            Relevant      True  \n",
      "3  pandemic death -0.145604    10    False          Irrelevant     False  \n",
      "4  pandemic death -0.117807     7    False          Irrelevant     False  \n",
      "5  pandemic death -0.122168     8    False          Irrelevant     False  \n",
      "6  pandemic death -4.994790    42    False          Irrelevant     False  \n",
      "7  pandemic death -0.116042     5    False          Irrelevant     False  \n",
      "8  pandemic death -0.159277    11    False          Irrelevant     False  \n",
      "9  pandemic death -0.116849     6    False          Irrelevant     False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2023 15:08:55] \"POST /feedback HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/Apr/2023 15:09:41] \"GET /query?searchString=pandemic%20death HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandemic death\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2023 15:09:49] \"OPTIONS /feedback HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      docno                                              title  \\\n",
      "0  ya9klbbm  Case-based reported mortality associated with ...   \n",
      "1  ao5676lc  Global Mortality Impact of the 1957–1959 Influ...   \n",
      "2  nqc1pduk  Natality Decline and Spatial Variation in Exce...   \n",
      "3  36fljyl2  Age-Specific Excess Mortality Patterns During ...   \n",
      "4  si9ty2dt  Dealing with mass death in disasters and pande...   \n",
      "5  vhghhvnu  Prioritization of Pandemic Influenza Vaccine: ...   \n",
      "6  tw2n8vqv  Seasonal and pandemic influenza during pregnan...   \n",
      "7  h7pteo3e  The 1918–1919 Influenza Pandemic in Portugal: ...   \n",
      "8  g0fu0r8r  Social Class and Excess Mortality in Sweden Du...   \n",
      "9  11r3dnse  Loose Ends in the Epidemiology of the 1918 Pan...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  BACKGROUND: In contrast to seasonal influenza ...   \n",
      "1  Background. Quantitative estimates of the glob...   \n",
      "2  A large body of epidemiologic research has con...   \n",
      "3  Although much progress has been made to uncove...   \n",
      "4  PURPOSE: There are many differences in how aut...   \n",
      "5  Few catastrophes can compare with the global i...   \n",
      "6  Previous studies of fetal death with maternal ...   \n",
      "7  Although the impact of deaths occurring during...   \n",
      "8  Consensus is lacking in the literature about t...   \n",
      "9  In the century since the 1918 influenza pandem...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  BACKGROUND: In contrast to seasonal influenza ...   \n",
      "1  Increases in the mortality rate relative to ba...   \n",
      "2  A large body of epidemiologic research has con...   \n",
      "3  Although much progress has been made to uncove...   \n",
      "4  PURPOSE: There are many differences in how aut...   \n",
      "5  Public health measures such as reduction of cl...   \n",
      "6  We obtained dates and types of influenza vacci...   \n",
      "7  Poisson regression was used to estimate the as...   \n",
      "8  We analyzed individual-level mortality of the ...   \n",
      "9  We analyze age-stratified mortality data from ...   \n",
      "\n",
      "                                             KeyList  \\\n",
      "0  [seasonal influenza epidemics, deaths, extent ...   \n",
      "1  [pandemic-related mortality, influenza pandemi...   \n",
      "2  [influenza pandemic, birth records, death reco...   \n",
      "3  [influenza pandemic, respiratory excess death ...   \n",
      "4  [pandemics, disasters, mass death incidents, d...   \n",
      "5  [pandemic, vaccination, overall population mor...   \n",
      "6     [ili, fetal death, risk, pregnancy, diagnoses]   \n",
      "7  [influenza-related excess mortality, deaths, d...   \n",
      "8  [differences, influenza-associated deaths, exc...   \n",
      "9  [influenza pandemic, high death rates, signatu...   \n",
      "\n",
      "                                       context_key_1  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  death incidents involving disasters and pandem...   \n",
      "5  impact of a severe influenza pandemic . The 19...   \n",
      "6                                               None   \n",
      "7                                               None   \n",
      "8  this study , we analyzed differences in excess...   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_2  \\\n",
      "0  , where the majority of deaths occur amongst e...   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  during mass death incidents involving disaster...   \n",
      "5  USA to set priorities for vaccination in the s...   \n",
      "6                                               None   \n",
      "7  Although the impact of deaths occurring during...   \n",
      "8                                               None   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_3  \\\n",
      "0                                               None   \n",
      "1  of background levels in 39 countries in Europe...   \n",
      "2                                               None   \n",
      "3  relative magnitudes of 3 pandemic waves in the...   \n",
      "4                                               None   \n",
      "5                                               None   \n",
      "6  ) in pregnancy on the risk of fetal death , di...   \n",
      "7                                               None   \n",
      "8                                               None   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_4  \\\n",
      "0                                               None   \n",
      "1  mortality rate was 1.9/10 000 population ( 95 ...   \n",
      "2                                               None   \n",
      "3                                               None   \n",
      "4  in how authorities handle the dead during mass...   \n",
      "5                                               None   \n",
      "6  illness ( ILI ) in pregnancy on the risk of fe...   \n",
      "7                                               None   \n",
      "8  pandemic was measured as the number of deaths ...   \n",
      "9                                               None   \n",
      "\n",
      "                                       context_key_5  qid  docid  \\\n",
      "0                                               None    1    660   \n",
      "1  to estimate pandemic-related mortality in exce...    1   2123   \n",
      "2  We estimated the number of excess deaths and b...    1   3539   \n",
      "3                                               None    1   3778   \n",
      "4  The main objective of this study is to show th...    1   6321   \n",
      "5                                               None    1   7914   \n",
      "6  fetal death , distinguishing between diagnoses...    1  10795   \n",
      "7                                               None    1  12123   \n",
      "8  influenza-associated deaths during the 1918 pa...    1  12124   \n",
      "9                                               None    1  12125   \n",
      "\n",
      "            query     score  rank bntStyle relevanceToggleText  relevant  \n",
      "0  pandemic death -0.090548     3     True            Relevant      True  \n",
      "1  pandemic death -0.057910     0     True            Relevant      True  \n",
      "2  pandemic death -0.141249     9     True            Relevant      True  \n",
      "3  pandemic death -0.145604    10    False          Irrelevant     False  \n",
      "4  pandemic death -0.117807     7    False          Irrelevant     False  \n",
      "5  pandemic death -0.122168     8    False          Irrelevant     False  \n",
      "6  pandemic death -4.994790    42    False          Irrelevant     False  \n",
      "7  pandemic death -0.116042     5    False          Irrelevant     False  \n",
      "8  pandemic death -0.159277    11    False          Irrelevant     False  \n",
      "9  pandemic death -0.116849     6    False          Irrelevant     False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Apr/2023 15:10:47] \"POST /feedback HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = flask.Flask(__name__)\n",
    "\n",
    "CORS(app)\n",
    "@app.route('/query', methods=['GET'])\n",
    "def search():\n",
    "    query = request.args.get('searchString')\n",
    "    print(query)\n",
    "    # start of permanent code\n",
    "    # searchResults = search_query(query, 'search_result_hosBedAvb.csv')\n",
    "    # start of permanent code\n",
    "\n",
    "    # start of temporary code\n",
    "    # searchResults = pd.read_csv('search_result_cough.csv')\n",
    "    # searchResults = pd.read_csv('search_result_covid.csv')\n",
    "    # searchResults = pd.read_csv('search_result_pandemic.csv')\n",
    "    searchResults = pd.read_csv('search_result_pandemicDeath.csv')\n",
    "    # searchResults = pd.read_csv('search_result_dryCough.csv')\n",
    "    # searchResults = pd.read_csv('search_result_hosBedAvb.csv')\n",
    "    searchResults.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    searchResults['KeyList'] = searchResults['KeyList'].apply(ast.literal_eval)\n",
    "    # end of temporary code\n",
    "\n",
    "    global query_df\n",
    "    query_dict = {'query': [query], 'query_vec' : [np.nan], 'new_query_vec' : [np.nan] }\n",
    "    query_df = pd.DataFrame(data=query_dict, index=[0])\n",
    "    return searchResults.to_json(orient='records')\n",
    "\n",
    "# Feedback\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def fetchFeedback():\n",
    "    global reranked_df\n",
    "    feedbackJson = request.json['updates']\n",
    "    relevanceList = []\n",
    "    if len(feedbackJson):\n",
    "        for doc in feedbackJson:\n",
    "            for relevance in doc['value']:\n",
    "                relevanceList.append(relevance)\n",
    "    feedback_df = pd.DataFrame(relevanceList)\n",
    "    print(feedback_df.head(10))\n",
    "    reranked_df = get_reranking(feedback_df, 0.3, 0.7)\n",
    "    feedback_df= reranked_df.drop(reranked_df[reranked_df['bntStyle'] == False].index)\n",
    "    return feedback_df.to_json(orient='records')\n",
    "\n",
    "@app.route('/plot')\n",
    "def plot():\n",
    "    # Generate the plot\n",
    "    fig = generate_plot2()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    output = io.BytesIO()\n",
    "    canvas.print_png(output)\n",
    "    response = Response(output.getvalue(), mimetype='image/png')\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0',port=5254)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}