{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install sumy"
   ],
   "metadata": {
    "id": "Oo_VGla98cCW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zuC2wGcI8LPV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing"
   ],
   "metadata": {
    "id": "AQLrhUvxB9PR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('/content/drive/MyDrive/ir_datasets/cord19.csv')\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "yBJtvkeTkgzR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "25cdeb9d-13c0-400c-adbe-2a77b8a56bcd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192509 entries, 0 to 192508\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  192509 non-null  int64 \n",
      " 1   docno       192509 non-null  object\n",
      " 2   title       192459 non-null  object\n",
      " 3   abstract    137644 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "jJrshfTLnMtz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b2ac6fc4-d9ca-4ccf-a0ae-79300ecc9244",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192509 entries, 0 to 192508\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   docno     192509 non-null  object\n",
      " 1   title     192459 non-null  object\n",
      " 2   abstract  137644 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "Vn46o1JOn-kr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "64f20fd4-db6e-4105-f8c8-eabde49b80f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 192100 entries, 0 to 192508\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   docno     192100 non-null  object\n",
      " 1   title     192050 non-null  object\n",
      " 2   abstract  137485 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "3gvMMN9qsiBm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "36131322-104c-4b03-bc92-02d80400ee8f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 137479 entries, 0 to 192506\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   docno     137479 non-null  object\n",
      " 1   title     137479 non-null  object\n",
      " 2   abstract  137479 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.to_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19.csv')"
   ],
   "metadata": {
    "id": "6bfMjaUZB3tT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary"
   ],
   "metadata": {
    "id": "xs6CsmwjBx4g",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# One time installation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "id": "lITJg9RsDLI8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19.csv')\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "VIswXqgTtn6o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating text parser using tokenization\n",
    "def get_summary(text, summarizer_lsa):\n",
    "  parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "  summary_2 = summarizer_lsa(parser.document, 2)\n",
    "  dp = []\n",
    "  for i in summary_2:\n",
    "    lp = str(i)\n",
    "    dp.append(lp)\n",
    "  final_sentence = ' '.join(dp)\n",
    "  return final_sentence"
   ],
   "metadata": {
    "id": "yd-Wfq-F8Shd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "summarizer_lsa = LsaSummarizer()\n",
    "dataset['summary'] = ''\n",
    "for index, row in dataset.iterrows():\n",
    "    dataset.at[index, 'summary'] = get_summary(row['abstract'], summarizer_lsa)\n",
    "dataset.to_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19_sum.csv')"
   ],
   "metadata": {
    "id": "wxIJFjVD8f8X",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.info()"
   ],
   "metadata": {
    "id": "zExu8E2dHg3R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'], inplace=True)"
   ],
   "metadata": {
    "id": "8DYJatbpHk2_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "ILmkkifkHvXV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.to_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19_sumy.csv')"
   ],
   "metadata": {
    "id": "PSCxIjd5H3Xa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KeyPhrasification"
   ],
   "metadata": {
    "id": "gZoaiVv8HJsb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19_sumy.csv')\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "WYfyPDpdCyPf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def getKeys(extractor, text):\n",
    "    extractor.load_document(input=text, language='en')\n",
    "\n",
    "    # identify the keyphrase candidates using TopicRank's default strategy\n",
    "    # i.e. the longest sequences of nouns and adjectives `(Noun|Adj)*`\n",
    "    extractor.candidate_selection()\n",
    "\n",
    "    # identifying keyphrase candidates populates the extractor.candidates dictionary\n",
    "    # let's have a look at the keyphrase candidates\n",
    "    # for each keyphrase candidate\n",
    "    # In TopicRank, candidate weighting is a three-step process:\n",
    "    #  1. candidate clustering (grouping keyphrase candidates into topics)\n",
    "    #  2. graph construction (building a complete-weighted-graph of topics)\n",
    "    #  3. rank topics (nodes) using a random walk algorithm\n",
    "    extractor.candidate_weighting()\n",
    "\n",
    "    # Get the N-best candidates (here, 5) as keyphrases\n",
    "    keyphrases = extractor.get_n_best(n=5, stemming=False)\n",
    "    keyphrasesList = []\n",
    "    for i, (candidate, score) in enumerate(keyphrases):\n",
    "        keyphrasesList.append(candidate)\n",
    "        print()\n",
    "    return keyphrasesList"
   ],
   "metadata": {
    "id": "3Y3lHnArJcQc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/boudinfl/pke.git"
   ],
   "metadata": {
    "id": "bJUmG_6zO-Bv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pke"
   ],
   "metadata": {
    "id": "y8FV_gRwPM3N",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "extractor = pke.unsupervised.TopicRank()\n",
    "dataset['KeyList'] = ''\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    dataset.at[index, 'KeyList'] = getKeys(extractor, row['abstract'])\n",
    "dataset.to_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19_key.csv')"
   ],
   "metadata": {
    "id": "UIJ0KOnGJ0aZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Context Extraction"
   ],
   "metadata": {
    "id": "lK29A2js8-M1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "dataset = pd.read_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19_key_clean.csv')\n",
    "dataset.info()"
   ],
   "metadata": {
    "id": "6LzAf-I89jXH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "id": "IJjRS1Y2Pnw2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# function to extract 5 words before and after a given word\n",
    "def extract_context(text, keyword):\n",
    "    # split the text into sentences using NLTK's sent_tokenize() function\n",
    "    sentences = sent_tokenize(text)\n",
    "    # iterate through each sentence\n",
    "    context = []\n",
    "    for sentence in sentences:\n",
    "        # split the sentence into words using NLTK's word_tokenize() function\n",
    "        words = word_tokenize(sentence)\n",
    "        # check if the keyword is present in the sentence\n",
    "        if keyword in words:\n",
    "            # find the index of the keyword in the sentence\n",
    "            keyword_index = words.index(keyword)\n",
    "            # find the start and end indices for the context\n",
    "            start_index = max(0, keyword_index - 5)\n",
    "            end_index = min(len(words), keyword_index + 6)\n",
    "            # extract the context and join the words together\n",
    "            context.append(' '.join(words[start_index:end_index]))\n",
    "    # join the contexts for each sentence together\n",
    "    return ' '.join(context) if context else ''"
   ],
   "metadata": {
    "id": "1DBmeJ9p9SJw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import ast\n",
    "for index, row in tqdm(dataset.iterrows(), total=dataset.shape[0]):\n",
    "  # print('Type of record: ', type(row['KeyList']))\n",
    "  keylist = ast.literal_eval(row['KeyList'])\n",
    "  for i in range(len(keylist)): \n",
    "    dataset.at[index, 'context_key_' + str(i + 1)] = extract_context(row['abstract'], keylist[i])"
   ],
   "metadata": {
    "id": "vdlQfIeR-dFj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop(dataset[dataset['KeyList'] == '[]'].index, inplace=True)"
   ],
   "metadata": {
    "id": "9G-227bsBTQ7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[dataset['docno']== 'vw8xjo9t']"
   ],
   "metadata": {
    "id": "fGFeXWLEAk6f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.drop(columns=['Unnamed: 0'], inplace = True)"
   ],
   "metadata": {
    "id": "rKKI-QrXTb2P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.fillna('', inplace=True)"
   ],
   "metadata": {
    "id": "sKja0KqbBX44",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset.to_csv('/content/drive/MyDrive/ir_datasets/cord19_final/cord19_context.csv', index=False)"
   ],
   "metadata": {
    "id": "CZESyDLVBmTt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset['abstract'][0]"
   ],
   "metadata": {
    "id": "XjGxj07vG20v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "lf77uEIokHXp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}